# -*- coding: utf-8 -*-
"""Symptom_Based_Disease_Prediction_Chatbot (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bFTGUM3Z4UCPQ3FAXHy_Aw6Y00iMLwrt

## Importing necessary libraries
"""

# Numpy and pandas for mathematical operations
import numpy as np
import pandas as pd

# To read csv dataset files
import csv

# Regular expression, for pattern matching
import re

# The preprocessing module provides functions for data preprocessing tasks such as scaling and handling missing data.
from sklearn import preprocessing

# For Visualization
import seaborn as sns
import matplotlib.pyplot as plt

# train-test split
from sklearn.model_selection import train_test_split

# For building decision tree models, and _tree to access low-level decision of tree structure
from sklearn.tree import DecisionTreeClassifier, _tree

# For evaluating model performance using cross_validation
from sklearn.model_selection import cross_val_score

# Import Support Vector Classification from sklearn library for model deployment
from sklearn.svm import SVC

# Remove unecessary warnings
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

"""## Text to speech using pyttsx3"""

!sudo apt-get install espeak

!pip install pyttsx3

import pyttsx3

engine = pyttsx3.init()

# def text_to_speech(text):
#     # Set properties (optional)
#     engine.setProperty('rate', 150)
#     engine.setProperty('volume', 0.9)


#     engine.say(text)
#     engine.runAndWait()

"""## Exploratory Data Analysis (EDA)

"""

import pandas as pd
training = pd.read_csv('/content/sample_data/Training.csv')
testing= pd.read_csv('/content/sample_data/Testing.csv')

shape = training.shape
print("Shape of Training dataset: ", shape)

description = training.describe()
description

info_df = training.info()
info_df

null_values_count = training.isnull().sum()
null_values_count

training.head(8)

cols= training.columns
cols= cols[:-1]

x = training[cols]

y = training['prognosis']

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(10, 20))
# Countplot from seaborn on the target varable and data accesed from Training dataset
sns.countplot(y='prognosis', data=training)
# Tile for title of the figur
plt.title('Distribution of Target (Prognosis)')
# Show used to display the figure on screen
plt.show()

reduced_data = training.groupby(training['prognosis']).max()

reduced_data.head()

"""## Data Pre-processing"""

from sklearn import preprocessing
# Mapping categorical strings to numerical labels using LabelEncoder
le = preprocessing.LabelEncoder()

# Fit the label encoder to the target variable 'y' and transform it
le.fit(y)
y = le.transform(y)

# Splitting the dataset into training and testing
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)

# Features for testing except the last variable
testx    = testing[cols]

# Target variable for Testing
testy    = testing['prognosis']

# Transforming categorical value into numerical labels
testy    = le.transform(testy)

"""## Model building and evaluation"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score


clf1  = DecisionTreeClassifier()

clf = clf1.fit(x_train,y_train)

scores = cross_val_score(clf, x_test, y_test, cv=3)

print("Mean Score: ",scores.mean())

# Creating Support Vector Machine Model
from sklearn.svm import SVC
import numpy as np

model=SVC()

# Train the model on Training Data
model.fit(x_train,y_train)

# Print accuracy for SVM Model on the training set
print("Accuracy score for svm: ", model.score(x_test,y_test))

# Calculate feature importance using the trained Decision tree classifier
importances = clf.feature_importances_

# Sort indices in descending order based on feature importance
indices = np.argsort(importances)[::-1]

# Get feature names corresponding to their importance score
features = cols

import pickle

# Save the trained Decision Tree model
with open('decision_tree_model.pkl', 'wb') as f:
    pickle.dump(clf, f)

# Save the LabelEncoder
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(le, f)

# Save the feature columns (symptom names)
with open('feature_columns.pkl', 'wb') as f:
    pickle.dump(cols, f)

# Initialize dictionaries to store symptom severity, description, and precautions

severityDictionary=dict()
description_list = dict()
precautionDictionary=dict()

# Dictionary to map symptoms to their indices
symptoms_dict = {}

# Populate symptoms dictionary with indices
for index, symptom in enumerate(x):
       symptoms_dict[symptom] = index

# Function to calculate the overall severity of the symptom
def calc_condition(exp,days):
    sum=0
    for item in exp:
         sum=sum+severityDictionary[item]
    if((sum*days)/(len(exp)+1)>13):
        print("You should take the consultation from doctor. ")
    else:
        print("It might not be that bad but you should take precautions.")


# Function to read and store symptom descriptions from a CSV file
def getDescription():
    global description_list
    with open('/content/sample_data/symptom_Description.csv') as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        line_count = 0
        for row in csv_reader:
            _description={row[0]:row[1]}
            description_list.update(_description)



# Function to read and store symptom severity information from a CSV file
def getSeverityDict():
    global severityDictionary
    with open('/content/sample_data/Symptom_severity.csv') as csv_file:

        csv_reader = csv.reader(csv_file, delimiter=',')
        line_count = 0
        try:
            for row in csv_reader:
                _diction={row[0]:int(row[1])}
                severityDictionary.update(_diction)
        except:
            pass



# Function to read and store symptom precaution information from a CSV file
def getprecautionDict():
    global precautionDictionary
    with open('/content/sample_data/symptom_precaution.csv') as csv_file:

        csv_reader = csv.reader(csv_file, delimiter=',')
        line_count = 0
        for row in csv_reader:
            _prec={row[0]:[row[1],row[2],row[3],row[4]]}
            precautionDictionary.update(_prec)

def getInfo():
    print("-----------------------------------HealthCare ChatBot-----------------------------------")
    print("\nYour Name? \t\t\t\t",end="->")
    name=input("")
    print("Hello", name)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix

# Make predictions on test data
y_pred = decision_tree_model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)

# Calculate precision, recall, F1 for each disease class
precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)

# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

def check_pattern(dis_list,inp):
    pred_list=[]
    inp=inp.replace(' ','_')
    patt = f"{inp}"
    regexp = re.compile(patt)
    pred_list=[item for item in dis_list if regexp.search(item)]
    if(len(pred_list)>0):
        return 1,pred_list
    else:
        return 0,[]

def sec_predict(symptoms_exp):
    df = pd.read_csv('/content/sample_data/Training.csv')
    X = df.iloc[:, :-1]
    y = df['prognosis']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)
    rf_clf = DecisionTreeClassifier()
    rf_clf.fit(X_train, y_train)

    symptoms_dict = {symptom: index for index, symptom in enumerate(X)}
    input_vector = np.zeros(len(symptoms_dict))
    for item in symptoms_exp:
      input_vector[[symptoms_dict[item]]] = 1

    return rf_clf.predict([input_vector])

def print_disease(node):
    node = node[0]
    val  = node.nonzero()
    disease = le.inverse_transform(val[0])
    return list(map(lambda x:x.strip(),list(disease)))

# Initialize the text-to-speech engine
from sklearn.tree import _tree
import re
import csv
engine = pyttsx3.init()

def tree_to_code(tree, feature_names):
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]

    chk_dis=",".join(feature_names).split(",")
    symptoms_present = []

    while True:

      # Prompt the user to enter the symptom
        engine.say("\n Enter the symptom you are experiencing \t\t\t",)
        engine.runAndWait()
        print("\nEnter the symptom you are experiencing  \t\t",end="->")
        disease_input = input("")

        conf,cnf_dis=check_pattern(chk_dis,disease_input)
        if conf==1:
            print("searches related to input: ")
            for num,it in enumerate(cnf_dis):
                print(num,")",it)
            if num!=0:
                print(f"Select the one you meant (0 - {num}):  ", end="")
                conf_inp = int(input(""))
            else:
                conf_inp=0

            disease_input=cnf_dis[conf_inp]
            break
        else:
            print("Enter valid symptom.")

    while True:
        try:
            num_days=int(input("Okay. From how many days ? : "))
            break
        except:
            print("Enter valid input.")
    def recurse(node, depth):
        indent = "  " * depth
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]

            if name == disease_input:
                val = 1
            else:
                val = 0
            if  val <= threshold:
                recurse(tree_.children_left[node], depth + 1)
            else:
                symptoms_present.append(name)
                recurse(tree_.children_right[node], depth + 1)
        else:
            present_disease = print_disease(tree_.value[node])

            red_cols = reduced_data.columns
            symptoms_given = red_cols[reduced_data.loc[present_disease].values[0].nonzero()]

            engine.say("Are you experiencing any")
            engine.runAndWait()
            print("Are you experiencing any ")
            symptoms_exp=[]
            for syms in list(symptoms_given):
                inp=""
                engine.say(f"{syms}, are you experiencing it?")
                engine.runAndWait()
                print(syms,"? : ",end='')
                while True:
                    inp=input("")
                    if(inp=="yes" or inp=="no"):
                        break
                    else:
                        print("provide proper answers i.e. (yes/no) : ",end="")
                if(inp=="yes"):
                    symptoms_exp.append(syms)

            second_prediction=sec_predict(symptoms_exp)
            # print(second_prediction)
            calc_condition(symptoms_exp,num_days)
            if(present_disease[0]==second_prediction[0]):
                engine.say("You may have ", present_disease[0])
                engine.runAndWait()
                print("You may have ", present_disease[0])
                print(description_list[present_disease[0]])


            else:
                engine.say(f"You may have {present_disease[0]} or {second_prediction[0]}.")
                engine.runAndWait()
                print("You may have ", present_disease[0], "or ", second_prediction[0])
                print(description_list[present_disease[0]])
                print(description_list[second_prediction[0]])

            # print(description_list[present_disease[0]])
            precution_list=precautionDictionary[present_disease[0]]
            print("Take following measures : ")
            for  i,j in enumerate(precution_list):
                print(i+1,")",j)


    recurse(0, 1)
getSeverityDict()
getDescription()
getprecautionDict()
getInfo()
tree_to_code(clf,cols)
print("----------------------------------------------------------------------------------------------------------------------------------")

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
import pickle

# Assuming the following objects are already defined from the original script:
# clf: Trained Decision Tree Classifier
# model: Trained SVM model
# x_test, y_test: Test features and labels
# le: LabelEncoder for prognosis
# cols: Feature columns (symptoms)

# Load pickled objects (if not already in memory)
try:
    with open('decision_tree_model.pkl', 'rb') as f:
        clf = pickle.load(f)
    with open('label_encoder.pkl', 'rb') as f:
        le = pickle.load(f)
except FileNotFoundError:
    print("Error: Pickled model or label encoder not found. Please run the training script first.")
    exit()

# Evaluate Decision Tree
dt_predictions = clf.predict(x_test)
dt_accuracy = accuracy_score(y_test, dt_predictions)
dt_report = classification_report(y_test, dt_predictions, target_names=le.classes_, output_dict=True)
dt_conf_matrix = confusion_matrix(y_test, dt_predictions)
dt_cv_scores = cross_val_score(clf, x_test, y_test, cv=5)  # Using 5-fold CV for better stability

# Evaluate SVM
svm_predictions = model.predict(x_test)
svm_accuracy = accuracy_score(y_test, svm_predictions)
svm_report = classification_report(y_test, svm_predictions, target_names=le.classes_, output_dict=True)
svm_conf_matrix = confusion_matrix(y_test, svm_predictions)

# Format output for text file
output = []
output.append("=== Model Evaluation Metrics ===\n")

# Decision Tree Metrics
output.append("Decision Tree Classifier\n")
output.append(f"Accuracy: {dt_accuracy:.4f}\n")
output.append("Cross-Validation Scores (5-fold):")
output.append(f"  Mean: {dt_cv_scores.mean():.4f}")
output.append(f"  Std: {dt_cv_scores.std():.4f}\n")
output.append("Classification Report:")
for label, metrics in dt_report.items():
    if isinstance(metrics, dict):  # Per-class metrics
        output.append(f"  {label}:")
        output.append(f"    Precision: {metrics['precision']:.4f}")
        output.append(f"    Recall: {metrics['recall']:.4f}")
        output.append(f"    F1-Score: {metrics['f1-score']:.4f}")
output.append("\n")

# SVM Metrics
output.append("SVM Classifier\n")
output.append(f"Accuracy: {svm_accuracy:.4f}\n")
output.append("Classification Report:")
for label, metrics in svm_report.items():
    if isinstance(metrics, dict):  # Per-class metrics
        output.append(f"  {label}:")
        output.append(f"    Precision: {metrics['precision']:.4f}")
        output.append(f"    Recall: {metrics['recall']:.4f}")
        output.append(f"    F1-Score: {metrics['f1-score']:.4f}")
output.append("\n")

# Save metrics to a text file
with open('model_evaluation_metrics.txt', 'w') as f:
    f.write("\n".join(output))

# Plot Confusion Matrix for Decision Tree
plt.figure(figsize=(10, 8))
sns.heatmap(dt_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Decision Tree Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('dt_confusion_matrix.png')
plt.close()

# Plot Confusion Matrix for SVM
plt.figure(figsize=(10, 8))
sns.heatmap(svm_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('SVM Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('svm_confusion_matrix.png')
plt.close()

print("Evaluation metrics saved to 'model_evaluation_metrics.txt'")
print("Confusion matrix plots saved as 'dt_confusion_matrix.png' and 'svm_confusion_matrix.png'")

=== Model Evaluation Metrics ===

Decision Tree Classifier
Accuracy: 0.XXXX
Cross-Validation Scores (5-fold):
  Mean: 0.XXXX
  Std: 0.XXXX
Classification Report:
  Disease_1:
    Precision: 0.XXXX
    Recall: 0.XXXX
    F1-Score: 0.XXXX
  Disease_2:
    Precision: 0.XXXX
    Recall: 0.XXXX
    F1-Score: 0.XXXX
  ...

SVM Classifier
Accuracy: 0.XXXX
Classification Report:
  Disease_1:
    Precision: 0.XXXX
    Recall: 0.XXXX
    F1-Score: 0.XXXX
  Disease_2:
    Precision: 0.XXXX
    Recall: 0.XXXX
    F1-Score: 0.XXXX
  ...